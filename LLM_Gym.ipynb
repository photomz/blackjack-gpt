{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy0WBwjDNOwT",
        "outputId": "9eca8431-fafd-4c3a-dc8f-f75c22a75888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install -q gymnasium openai datasets accelerate tqdm bitsandbytes git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nd6LLEl9VCT0"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"YOUR_API_KEY\")\n",
        "\n",
        "\n",
        "def gpt(messages) -> str:\n",
        "    messages.insert(\n",
        "        0,\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"You are an expert blackjack player. On each turn, you will receive 3 values: your current sum (4 - 12), dealer's showing card value (2 - 11), whether there is a usable ace (0 or 1). Decide whether to stick or hit by writing \"Action: 0\" or \"Action: 1\" respectively. You MUST decide your action.\"\"\",\n",
        "        },\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages  # [\n",
        "        #   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        #   {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
        "        #   {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
        "        #   {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
        "        # ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RfRK1oYTZb73"
      },
      "outputs": [],
      "source": [
        "def format_observation(d) -> str:\n",
        "    # # i.e. Sum is 14, dealer is 6, no ace.\n",
        "    return f\"Sum is {d[0]}, dealer is {d[1]}, {'have' if bool(d[2]) else 'no'} ace\"\n",
        "\n",
        "\n",
        "def extract_action(response) -> int:\n",
        "    digits = [char for char in response if char.isdigit()]\n",
        "    if len(digits) == 0:\n",
        "        raise ValueError(\"No action chosen\")\n",
        "    else:\n",
        "        return int(digits[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tBkDDY66kdUi"
      },
      "outputs": [],
      "source": [
        "def llama(messages) -> str:\n",
        "    prompt = llama_pipe.tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    outputs = llama_pipe(\n",
        "        [prompt],\n",
        "        batch_size=1,\n",
        "        max_new_tokens=16,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "\n",
        "    print(outputs[0][0][\"generated_text\"])\n",
        "    response = outputs[0][0][\"generated_text\"].split(\"<|assistant|>\\n\")[-1]\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "35dfe9154e524f5aaf6b94433731c84d",
            "0d05d461eefd48c4ae022eafc91c9397",
            "7307e12231da4614af5040eedcddd38b",
            "cd6f144ce5cd446ca8864272c4ae8212",
            "0ae2ee341305493a9456feeb23793f95",
            "ebc86cb3fa084cabb85051b7c0748ae3",
            "0c6f6bd709604d61b61262c6e95208fd",
            "cbdba02235ea497ea55a388605b70b24",
            "d244d2ee4fc84a2ea0b3b00a728fb020",
            "00f40631516b4bda9f23ec1702485ec5",
            "f02d66f0824d444388a5a8425b5c17d4"
          ]
        },
        "id": "UOeUZOLTlER8",
        "outputId": "a4af4a27-55ca-4e80-84fe-24c5e1a279bb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35dfe9154e524f5aaf6b94433731c84d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from google.colab import userdata\n",
        "\n",
        "llama_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    token=userdata.get(\"HF_TOKEN\"),\n",
        "    model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    device_map=\"auto\",\n",
        "    model_kwargs={\"load_in_8bit\": True},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_rZGCI8Ok4Z",
        "outputId": "a89e2fe7-0921-4136-b13e-b0dca649f930"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>[INST] <<SYS>>\n",
            "You are an expert single-player blackjack player. Every turn, you'll see your current sum, the dealer's showing card value (1 of 2), and whether you have a usable ace. You win by (1) not exceeding 21, and (2) exceeding the dealer's hand -- hidden+showing card values.\n",
            "\n",
            "Decide whether to stick or hit by writing \"Action: 0\" or \"Action: 1\" respectively. You MUST decide your action and remember to write \"Action:\".\n",
            "<</SYS>>\n",
            "\n",
            "Sum is 15, dealer is 2, no ace [/INST]  Action: 0\n",
            "RESET (15, 2, 0), 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import trange\n",
        "import gymnasium as gym\n",
        "\n",
        "env = gym.make(\"Blackjack-v1\", natural=False, sab=False)\n",
        "\n",
        "observation, info = env.reset(seed=42)\n",
        "trajectories = []\n",
        "\n",
        "for episode in trange(1):\n",
        "    episode_messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"You are an expert single-player blackjack player. Every turn, you'll see your current sum, the dealer's showing card value (1 of 2), and whether you have a usable ace. You win by (1) not exceeding 21, and (2) exceeding the dealer's hand -- hidden+showing card values.\n",
        "\n",
        "Decide whether to stick or hit by writing \"Action: 0\" or \"Action: 1\" respectively. You MUST decide your action and remember to write \"Action:\".\"\"\",\n",
        "        }\n",
        "    ]\n",
        "    while True:\n",
        "        # print(f\"Observation: {observation}\")\n",
        "\n",
        "        message = format_observation(observation)\n",
        "        episode_messages += [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "        response = llama(episode_messages)\n",
        "        action = extract_action(response)\n",
        "\n",
        "        episode_messages += [{\"role\": \"assistant\", \"content\": str(action)}]\n",
        "        # print(f\"Action: {action}\")\n",
        "\n",
        "        observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        if terminated or truncated:\n",
        "            print(f\"RESET {observation}, {reward}\")\n",
        "            observation, info = env.reset()\n",
        "            trajectories.append((episode_messages, observation, reward))\n",
        "            break\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8LxocFIiJ_6",
        "outputId": "20259fde-560d-4816-86b2-3f6c083ccb99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "avg_reward = sum([reward for _, _, reward in trajectories]) / len(trajectories)\n",
        "print(avg_reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnG4HDh2AUOf",
        "outputId": "58a9c2fd-d7c7-4389-be4b-b979c17814f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "  6%|▌         | 62/1000 [02:44<42:34,  2.72s/it, win=-.238]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "from google.colab import userdata\n",
        "import gymnasium as gym\n",
        "from gymnasium.vector import SyncVectorEnv\n",
        "from tqdm import trange\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "bs = 8\n",
        "steps = 1000\n",
        "seeds = [42 * n for n in range(bs)]\n",
        "system_message = \"\"\"You are an expert single-player blackjack player. Every turn, you'll see your current sum, the dealer's showing card value (1 of 2), and whether you have a usable ace. You win by (1) not exceeding 21, and (2) exceeding the dealer's hand -- hidden+showing card values.\n",
        "\n",
        "Decide to stick or hit by answering \"Action: 0\" or \"Action: 1\" respectively. You MUST choose one of 2 options; none else.\"\"\"\n",
        "\n",
        "# Language Model Pipeline\n",
        "# llama_pipe = pipeline(\"text-generation\", token=userdata.get('HF_TOKEN'), model=\"meta-llama/Llama-2-7b-chat-hf\", device_map=\"auto\", model_kwargs={\"load_in_8bit\": True})\n",
        "llama_pipe.tokenizer.pad_token_id = llama_pipe.model.config.eos_token_id\n",
        "\n",
        "\n",
        "# Function to generate responses for a batch of messages\n",
        "def llama_batch(messages_batch):\n",
        "    prompts = [\n",
        "        llama_pipe.tokenizer.apply_chat_template(\n",
        "            messages, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "        for messages in messages_batch\n",
        "    ]\n",
        "    outputs = llama_pipe(\n",
        "        prompts,\n",
        "        batch_size=bs,\n",
        "        max_new_tokens=16,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "\n",
        "    responses = [output[0][\"generated_text\"].split(\n",
        "        \"\\n\")[-1] for output in outputs]\n",
        "    return responses\n",
        "\n",
        "\n",
        "# Function to format observations for all environments\n",
        "def format_observations(observations):\n",
        "    formatted_messages = []\n",
        "    player_hand, dealer_showing, usable_ace = observations\n",
        "    for A, B, C in zip(player_hand, dealer_showing, usable_ace):\n",
        "        message = f\"Your hand: {A}, Dealer's showing: {B}, Usable ace: {'yes' if C else 'no'}.\"\n",
        "        formatted_messages.append(message)\n",
        "    return formatted_messages\n",
        "\n",
        "\n",
        "# Function to extract actions from responses\n",
        "def extract_actions(responses):\n",
        "    actions = []\n",
        "    for response in responses:\n",
        "        if \"Action: 1\" in response:\n",
        "            actions.append(1)  # Hit\n",
        "        elif \"Action: 0\" in response:\n",
        "            actions.append(0)  # Stand or default action\n",
        "        else:\n",
        "            raise NotImplementedError(f'Generated invalid action \"{response}\"')\n",
        "    return actions\n",
        "\n",
        "\n",
        "# Create multiple environments\n",
        "def make_env():\n",
        "    return gym.make(\"Blackjack-v1\", natural=False, sab=False)\n",
        "\n",
        "\n",
        "envs = SyncVectorEnv([make_env for _ in range(bs)])\n",
        "trajectories = []\n",
        "\n",
        "# Run episodes\n",
        "try:\n",
        "    for episode in (pbar := trange(steps)):\n",
        "        observations, infos = envs.reset()\n",
        "        episode_messages_batch = [\n",
        "            [{\"role\": \"system\", \"content\": system_message}] for _ in range(16)\n",
        "        ]\n",
        "\n",
        "        while True:\n",
        "            messages_batch = format_observations(observations)\n",
        "            episode_messages_batch = [\n",
        "                episode_messages + [{\"role\": \"user\", \"content\": message}]\n",
        "                for episode_messages, message in zip(\n",
        "                    episode_messages_batch, messages_batch\n",
        "                )\n",
        "            ]\n",
        "\n",
        "            responses = llama_batch(episode_messages_batch)\n",
        "            actions = extract_actions(responses)\n",
        "\n",
        "            episode_messages_batch = [\n",
        "                episode_messages\n",
        "                + [{\"role\": \"assistant\", \"content\": f\"Action: {action}\"}]\n",
        "                for episode_messages, action in zip(episode_messages_batch, responses)\n",
        "            ]\n",
        "\n",
        "            observations, rewards, terminated, truncated, infos = envs.step(\n",
        "                actions)\n",
        "\n",
        "            # print(observations, '\\n\\n', rewards, '\\n\\n',  terminated, '\\n\\n', truncated, '\\n\\n', infos)\n",
        "\n",
        "            if all(terminated) or all(truncated):\n",
        "                # Access final observation and info if needed\n",
        "                # final_observation = info.get('final_observation')\n",
        "                # final_info = info.get('final_info')\n",
        "\n",
        "                batch = [(x, y)\n",
        "                         for x, y in zip(episode_messages_batch, rewards)]\n",
        "                trajectories += batch\n",
        "                avg_reward = sum([y for (_, y) in trajectories]\n",
        "                                 ) / len(trajectories)\n",
        "                pbar.set_postfix(win=avg_reward)\n",
        "\n",
        "            # Check if all environments have terminated\n",
        "            if all(terminated):\n",
        "                break\n",
        "finally:\n",
        "    envs.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNhI3qcoMVeK"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset = {\n",
        "    \"prompt\": [x for (x, _) in trajectories],\n",
        "    \"label\": [y for (_, y) in trajectories],\n",
        "}\n",
        "\n",
        "dataset = Dataset.from_dict(dataset).train_test_split(test_size=0.1)\n",
        "print(type(dataset))\n",
        "\n",
        "dataset.push_to_hub(\"photonmz/blackjack-gpt\", token=\"YOUR_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYrX0Hi6iewS"
      },
      "source": [
        "# Scores\n",
        "\n",
        "- Random (n=100): -0.27\n",
        "- Llama2-7b-chat (n=100): -0.39 -> -0.19\n",
        "- GPT-3.5-Turbo (n=100): -0.19\n",
        "- GPT-4 (n=100): -0.14\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00f40631516b4bda9f23ec1702485ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae2ee341305493a9456feeb23793f95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c6f6bd709604d61b61262c6e95208fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d05d461eefd48c4ae022eafc91c9397": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebc86cb3fa084cabb85051b7c0748ae3",
            "placeholder": "​",
            "style": "IPY_MODEL_0c6f6bd709604d61b61262c6e95208fd",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "35dfe9154e524f5aaf6b94433731c84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d05d461eefd48c4ae022eafc91c9397",
              "IPY_MODEL_7307e12231da4614af5040eedcddd38b",
              "IPY_MODEL_cd6f144ce5cd446ca8864272c4ae8212"
            ],
            "layout": "IPY_MODEL_0ae2ee341305493a9456feeb23793f95"
          }
        },
        "7307e12231da4614af5040eedcddd38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbdba02235ea497ea55a388605b70b24",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d244d2ee4fc84a2ea0b3b00a728fb020",
            "value": 2
          }
        },
        "cbdba02235ea497ea55a388605b70b24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6f144ce5cd446ca8864272c4ae8212": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00f40631516b4bda9f23ec1702485ec5",
            "placeholder": "​",
            "style": "IPY_MODEL_f02d66f0824d444388a5a8425b5c17d4",
            "value": " 2/2 [01:09&lt;00:00, 32.02s/it]"
          }
        },
        "d244d2ee4fc84a2ea0b3b00a728fb020": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebc86cb3fa084cabb85051b7c0748ae3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f02d66f0824d444388a5a8425b5c17d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
